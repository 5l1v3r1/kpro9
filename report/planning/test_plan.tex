%==================
\chapter{Test Plan}
%==================
This chapter presents the test plan for our solution. The test plan is based on
the standards set by the IEEE829-1998 standard for software testing\cite{IEEE829}, but with a
few changes to better fit with our project. The purpose of this plan is to have
a structured way of performing tests, as well as providing the developers with
a list of specific component-behaviors. The tests will be based on functional as
well as non-functional requirements, deterring architectural drift and
enforcing our design plans for the system.


%----------------------------
\section{Methods for Testing}
%----------------------------
When it comes to software testing, we have 2 different types of tests available, namely Black box and white box tests. This section is dedicated to the discussion of these 2 testing methodologies.


%--------------------------
\subsection{White box Testing}
%--------------------------
White box testing is a method of software testing where you test internal structures or modules of an application, as opposed to its functions. White box testing requires the tester to have an internal perspective of the system, as well as sufficent programming skills. As the \gls{utility} was required to be able to function with a variety of different input, as well as being used as a debugging tool itself, we chose to have every developer on the team write unit tests for their own code, and then have someone else on the team do the testing of their code in order to ensure correctness. Also in order to get a proper overview over what and how many parts of the system that are covered by unit tests, the team decided to use a tool for measuring code coverage.

\subsubsection{Attest}
As a tool for creating white box unit tests the team decided to use the Attest testing framework for python code. To create unit tests using Attest, you start off by importing Tests, assert\_hook and optionally contexts from attest. You then create a variable and initialize it to an instance of Tests which is the variable which will contain a list functions that each constitutes one test that is to be run. To feed your test instance with functions for testing you then have to mark these functions with a decorator and feed it the .tests function of the Tests instance. After creating a unit test in this fashion you can run all of your unit tests through Attest from the command line by typing ''python -m attes''. This runs all of your unit tests through Attest and returns a message telling the user how many assertions failed as well as what input made them fail. For more information read the user documentation of Attest. 

\subsubsection{Coverage}
As a tool for calculating code coverage the team decided to use Coverage,which is a tool for measuring code coverage in python projects. In order to run Coverage from the command line with the tests for this utility you would have to first navigate to the folder where you installed CSjark, before typing "Coverage run -m attest". This generates a file which will be used to Coverage for generating a html table displaying the coverage. In order to create this html table you would then have to type "coverage html", which generates a folder named htmlcov. This htmlcov folder again contains a file named index.html which contains a html table describing which parts of the system underwent testing and their code coverage.


%--------------------------
\subsection{Black Box Testing}
%--------------------------
Black box testing is a method of software testing where you test the functionality of a system, as opposed to its internal structures. Black box testing does in general not require the tester to have any intimate knowledge about the system or any of the programming logic that went into making it. Black box test cases are built around the specifications and requirements of a system, i.e its functional and in some cases non-functional requirements. The team decided to use black box testing for both the functional and non-functional requirements of the \gls{utility}, as the customer had already expressed thoughts on extending and understanding the non-functional parts of the \gls{utility} themselves. 


%------------------------------
\section{Templates for Testing}
%------------------------------
\autoref{tab:testcase} , \autoref{tab:testreport} and \autoref{tab:TestCoverageReport} are templates we will be
using for testing purposes.

In order to standarize the testing process, the team decided on making templates for both the tests themselves and for reporting their results. The ones responsible for testing were given the task of filling out these tables to make sure they got filled out and stored properly.

\autoref{tab:testcase} shows the template for each test case. All of the test cases written for the \gls{utility} will be in this format, and executed according to this document.

\begin{table}[htb] \small \center
\caption{Test case template \label{tab:testcase}}
\begin{tabular}{l l}
	\toprule
	Header & Description \\
	\midrule
	Description & Description of requirement \\
	Tester & Team member responsible for the test \\
	Prerequisites & Conditions that needs to be fulfilled before starting the test \\
	Feature & Feature to test \\
	Execution & Steps to be executed in the test \\
	Expected result & The expected output of the test \\
	\bottomrule
\end{tabular}
\end{table}

\autoref{tab:testreport} shows the template for reporting the result of each test case.

\begin{table}[htb] \small \center
\caption{Test report template \label{tab:testreport}}
\begin{tabular}{l l}
	\toprule
	Header & Description \\
	\midrule
	Description & Description of requirement \\
	Tester & Team member responsible for the test \\
	Date & The date the testing took place \\
	Result & The success or failure of the test, and a comment on the result if needed \\
	\bottomrule
\end{tabular}
\end{table}

\autoref{tab:TestCoverageReport} shows the template for reporting code coverage.

\begin{table}[!htb]\footnotesize\center
	\caption{Code Coverage Report Template\label{tab:TestCoverageReport}}
	\begin{tabular}{l l l l l}
		\toprule
		Module & Statements & Missing & Excluded & Coverage\\
		\midrule
		module 1 & Statements ran & Statements not ran  & Excluded statements & Percent code coverage\ \\
		... & ... & ... & ... & ... \\
		module n & Statements ran & Statements not ran & Excluded statements  & Percent code coverage \\
		\bottomrule
		Total & Statements ran & Statements not ran & Excluded statements & Percent code coverage \\
		\bottomrule
	\end{tabular}
\end{table}


%-----------------------
\section{Test Criterias}
%-----------------------
An item will be considered to have passed a test if the actual result from the test matches the expected result from the test. An item will be considered to have failed the test if the output varies from the expected result. If there are any specifics as to why the test passed/failed which needs to be discussed, they will be listed as a comment to the result


%---------------------------------
\section{Testing Responsibilities}
%---------------------------------
Each team member is responsible for writing their own unit tests while the test leader is responsible for the quality of the test plan and the tests. The tests will mainly not be executed by the same developers who wrote the code that is to undergo testing, but by others in the testing team with as little ownership of the code as possible. 

%---------------------
\section{Changelog}
%----------------------

\subsection{Sprint 1}
%----------------------
During sprint 1 it became apparent that the customers would not be able to supply the team with any real traffic data to use for testing. The testing team therefore decided to use a hex-editor to generate their own data \glspl{packet} with the \Gls{c}-\glspl{struct} that would be used for testing the \gls{utility}. This is done by manually writing the hex values for the individual bytes in a pcap \gls{packet}, where the first byte indicates the version number, the second byte indicates the flag value of the \gls{packet} and where the third and fourth byte indicates the message ID. The rest of the bytes in the \gls{packet} then contain the \gls{member} values of whatever \gls{struct} was associated with the \gls{packet}'s message ID.

During the sprint it also became apparent that \Gls{wireshark} would be able to provide the developers and testers with feedback on syntax and user errors on both the \glspl{dissector} created by the \gls{utility}, as well as the traffic used for testing. This is done by \Gls{wireshark} crashing and/or providing the team with error messages related to which code in which \gls{dissector} is faulty. There will also be displayed a warning or error message with the generated traffic-data if there are any faults with them. The team was therefore able to use \Gls{wireshark} in assisting them in creating correct code early on before writing unit tests.   

\subsection{Sprint 2}
%----------------------
As of sprint 2 it was decided that the team should use an automated tool for calculating code coverage. Code coverage is a measure describing the actual amount of, and which code that undergoes unit testing. As code coverage inspects code directly, it is considered a form of white box testing. In this project it will be used to ensure that an as big part as possible of the system actually undergoes testing, and that the unit tests associated with the different modules of the \gls{utility} actually tests what they are supposed to. It was also added as a goal to have at least 80\% at the end of the project, where the testers and developers would aim to increase the amount of code coverage from each previous sprint.

\subsection{Sprint 3}
%----------------------
During sprint 3 it was suggested that the team should create a \Gls{c}-program that generates \glspl{hex dump} that were to be used for generating traffic to test the \gls{utility} with. It was therefore decided that the team would create such a program to generate data for the bigger and more complex \Gls{c}-\gls{header} files that could have a dozen of \gls{struct}-\glspl{member} of various types. This would help the team to be able to generate more test traffic for the most complex \glspl{header} without having to spend much extra time manually writing down the hex values of each \gls{struct} \gls{member}.

\subsection{Sprint 4}
%----------------------

