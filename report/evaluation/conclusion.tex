%===================
\chapter{Conclusion}
%===================
\label{cha:conclusion}
This chapter describes the final state of the product.


%------------------------
\section{System Overview}
%------------------------
\autoref{fig:logicalview} shows an overview of the final version of the
product. Our utility consist of seven Python modules:
\begin{itemize}
	\item csjark
	\item cpp
	\item cparser
	\item field
	\item dissector
	\item platform
\end{itemize}
The CSjark modules takes as input C header files and config files. Config
files are forward to the config module which reads them to find rules and
options.

CSjark then forward header files to the cpp module, which calls an external
program, a C preprocessor. The output of the C preprocessor is given to the
cparser module, which forwards it to the pycparser library. An abstract
syntax three is returned by pycparser, which is traversed by the cparser
module when it search for struct definitions.

The cparser module creates a Protocol instance from the dissector module for
each struct it finds. It creates 

%----------------------------
\section{Further Development}
%----------------------------
\label{sec:eval:furtherdev}
This section describes possible improvements to our utility.
In \autoref{sec:conc:optional} we describe how one might implement the remaining
optional requirements, while \autoref{sec:conc:addimps} list other improvements.

\subsection{Optional Requirements}
%---------------------------------
\label{sec:conc:optional}
During the third sprint, as we had completed most of the requirements given to
us, it became clear we would not have sufficient requirements for a fourth
sprint. We requested more possible features from the customer, who provided us
with a list of new functional requirements and their prioritization.

In the fourth sprint planning meeting, we estimated the work hours needed to
complete each of the new requirements, including implementation, testing and
documentation. Based on the customers prioritization and our estimates, we
classified four of them as optional, as we did not deem it possible to
fulfill them in the fourth sprint.

The customer asked us to provide a description of how the unfulfilled
requirements could be implemented, which is listed below.
\begin{enumerate}
\item Don't regenerate dissectors across multiple runs
\item Use Doxygen comments for "Description"	
\item Read int-enum config from header files
\item Display if struct member contains uninitialized memory
\end{enumerate}

\noindent The following paragraphs describe how they can be implemented.
\paragraph{Don't regenerate dissectors across multiple runs}
To be able to decide if we have already generated dissectors in earlier runs, we need to store some state on disk. 

We need to store the last modified timestamp, which the operating system reports, at the time we last read them. 
This needs to be done for each single input file, both header- and config files.
Since command line arguments will affect the output, they must also be stored. The main challenge with this task is the fact that handling \#include directives are performed by the external C preprocessor program, so we will not know which files need to be considered when evaluating, if files have been modified since last run.

One could look at \#line directives outputted by the C preprocessor before we start parsing files, but the benefit of not regenerating dissectors would be diminished.

We estimate this task would require implementing our own C preprocessor or using a library instead of an external tool, to be able to extract the needed file dependencies. Our utility depends on PLY, which have a 95\% finished implementation of a C preprocessor, which might prove valuable for this task.

When we are able to know which files depend on each other, and the last time they were modified, the task is simply to find a suitable data structure to store on disk between runs.

\paragraph{Use Doxygen comments for "Description"}
Comments are removed by the C preprocessor, which means we must parse them before it is run. As the preprocessor evaluates which files to open, we would be required to implement our own or use a library, or try to evaluate applicable files in all include folders.

The task, if such support was available, would simply be to search for doxygen comments, and when one is found parse it to extract the correct information.

\paragraph{Read int-enum config from header files}
Integers, which should act as enums in Wireshark, are defined by some specific C preprocessor macro define directives in the customer's current header files. This task is to automatically extract such information, to require less manual configuration of our utility.

Like the two previous task, this will require us to parse C preprocessor directives before they are removed by the C preprocessor, which means we must implement our own C preprocessor or use a library.

To avoid having to parse both C preprocessor directives and C code at the same time, we could design a syntax for describing which struct member(s) the macro define directives refer to. For example \#define BEGIN\_CSJARK\_ENUM\_FOR\_NAME could be placed right before the current enum macro directives start, which would tell us that they refer to struct member NAME.

This task becomes trivial to implement if we had a custom C preprocessor we could modify.

\paragraph{Display if struct member contains uninitialized memory}
Uninitialized memory will look different depending on the compiler, so therefore we need to add support for specifying how it will look for each Platform instance in platform module. Since we can only evaluate the actual memory on the Wireshark end of things, most of the functionality must be written in Lua code.

These two conditions suggest that the dissector module should, inside the Delegator class, generate a suitable Lua function in luastructs.lua which accepts a buffer value for a field and the field node. This function should, if the buffer value match uninitialized memory,  set an appropriate warning on the field node.

This new function must be called for every field defined in every dissector we generate, inside the appropriate dissector functions.

In addition to implementation, the task involves researching how uninitialized memory looks on different platforms we support, and creating pcap files for testing the functionality.

\subsection{Additional Improvements}
%-----------------------------------
\label{sec:conc:addimps}
In \autoref{sec:sp4:onsite} we described testing of our utility on customer's
code base. We discovered several corner cases which we did not support, and we
also found problems with memory consumption when number of input files was
over 1000. These problems could be solved by further development, which we
describe in following paragraphs.

\paragraph{Reduce memory consumption}
We did some basic profiling, both of memory and CPU usage, to evaluate what
could be improved. Almost all CPU usage was defined to the preprocessor and
the pycparser library, which means we could not find any possible improvements
in out utility.

Memory profiling on 1000 header files revealed that almost all memory was used
by Python dictionaries and lists. Our utility builds up a list of Protocol
instances which represent all structs we parse, before we write any to disk.
This grows as more files are parsed. A simple, but effective, solution would
be to write Protocols to disk as after we have parsed a single file. We would
still need to store a few attributes for each Protocol, such as name, id,
size. We believe this would reduce memory consumption sufficiently.

It is also possible that we leak some memory each time we fail to parse a
file, which could be investigated and fixed afterwards.

\paragraph{Additional C parsing support}
We successfully parsed 160 of 200 header files in customer's include folder,
the remaining files failed mostly from corner cases our utility did not
support, for example typedef's we had not considered. We believe it would be
relatively easy to add further support for them when they are discovered.

\paragraph{Less manual configuration}
Several of the optional requirements are focused on requiring less manual
configuration. If we perform the C preprocessing ourself instead of delegating
it to an external program, we would be able to read configuration from
comments and \#define's inside the header files.

%----------------
\section{Testing}
%----------------
At the beginning of the project all of the team members agreed that we were going to focus on doing extensive and proper testing of our utility. In this section we will discuss whether or not we were able to reach the goals we sat at the beginning and during the project.

\subsection{Methods}
%-------------------
At the beginning of the project we only used black box test cases and unit tests. We quickly found that even though we were able to uncover several bugs using these methods, it was hard to calculate what and how many parts of the system were actually undergoing testing. This again made it difficult to figure out the real quality of our tests and if our testing efforts were used to their true potential. When we then decided to use a tool for calculating code coverage we noticed that there were large parts of the system that were still untested even though the functionality of the system had been tested in our black box test cases. We therefore made a goal of trying to have a test coverage of at least 80\% in order to catch as many bugs as possible. This proved to be a hard task at first, but as can be seen in \autoref{fig:finalCodeCoverage}, once we got used to using a tool to calculate the coverage of our unit tests, we were able to improve the quality of our tests so that they covered more parts of the system.

\begin{figure}[htb]
	\center
	\includegraphics[width=\textwidth]{./sprints/img/sprint4_code_coverage_chart}
	\caption{Code Coverage Progress from Previous Sprints\label{fig:sp4CoverageChart}}
\end{figure}

\subsection{Testing Conclusion}
%------------------------------
After finishing the project we had uncovered several serious and many more non-critical bugs in our utility. We also discovered several bugs in the LUA-implementation of Wireshark that we needed to have our customer to fix. This proved to be very important as this severely reduced the amounts of bugfixes that had to be implemented after being allowed to send our developers to work with the utility at the customer-site. We were therefore able to create a working product within the small time-frame we had left after testing the utility at the customer-site. We therefore conclude that it had indeed been necessary to focus on creating extensive tests for the utility and that the methods we had chosen for testing were sufficient to get a working end-product.




%----------------
\section{Summary}
%----------------

